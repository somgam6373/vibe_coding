/*
í¬ë¡¤ë§ ì‚¬ì´íŠ¸ ë¶€í„°ëŠ” ìƒˆë¡œ ì•Œë ¤ì¤„ê²Œ 
https://www.imdb.com/?ref_=nm_nv_home
ë‚´ê°€ ë§Œë“¤ê³  ì‹¶ì€ ê¸°ëŠ¥ì„ ì•Œë ¤ì¤„ê²Œ
ì¼€ë¹ˆ ë² ì´ì»¨ ì˜ˆì œë¥¼ ì‹¤ì œ í¬ë¡¤ë§ì„ í†µí•´ì„œ êµ¬í˜„í•˜ëŠ”ê±°ì•¼ ì˜ˆì‹œë¡œ ë‘ ë°°ìš°ê°€ ìˆì„ë•Œ ê°™ì€ ì˜í™”ì— ì¶œí˜„í–ˆë‹¤ë©´ 1ë‹¨ê³„ ë‘ ë°°ìš° ì‚¬ì´ì— ë‘ ê°œì˜ ì˜í™”ê°€ ìˆë‹¤ë©´ 2ë‹¨ê³„ ì´ëŸ° ì‹ì´ì•¼ 

ìš°ì„  ì‚¬ìš©ìì—ê²Œ ë°°ìš° ì´ë¦„ ë‘ê°œë¥¼ ì…ë ¥ ë°›ì„ê±°ì•¼ ì²«ë²ˆì§¸ ì´ë¦„ì€ ê¸°ì¤€ì´ ë˜ëŠ” ë°°ìš°ì´ê³  ë‘ë²ˆì§¸ ë°°ìš° ì´ë¦„ì€ ê¸°ì¤€ì´ ë˜ëŠ” ë°°ìš°ì™€ ëª‡ë‹¨ê³„ë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ ì°¾ì„ ì´ë¦„ì´ì•¼ 
1. ìš°ì„  ì…ë ¥ë°›ì€ ì²« ë²ˆì§¸ ë°°ìš°ì˜ ì´ë¦„ì„ í†µí•´ í¬ë¡¤ë§ì„ ì´ìš©í•˜ì—¬ ê·¸ ë°°ìš°ê°€ ì¶œì—°í•œ ì˜í™”ë¥¼ ëª¨ë‘ ì°¾ì•„ 
2. ì°¾ì€ ì˜í™”ë¥¼ í†µí•´ ê·¸ ì˜í™”ì— ì¶œì—°í•œ ë°°ìš°ë¥¼ ëª¨ë‘ ì°¾ì•„ 
3. ê·¸ ë°°ìš°ë“¤ ì¤‘ì—ì„œ ì…ë ¥ë°›ì€ ë‘ ë²ˆì§¸ ë°°ìš°ê°€ ìˆë‹¤ë©´ ë°˜ë³µì„ ê·¸ë§Œí•˜ê³  ê²°ê³¼ë¥¼ ì•Œë ¤ì¤˜ 
4. ë§Œì•½ ì—†ë‹¤ë©´ ë‹¤ì‹œ 2ì—ì„œ ì°¾ì€ ë°°ìš°ë“¤ì´ ì¶œì—°í•œ ì˜í™”ë¥¼ ì°¾ì•„ ê°™ì€ ê³¼ì •ì„ ë°˜ë³µí•˜ëŠ”ê±°ì•¼ `


ì¼ë‹¨ ì´ ê¸°ëŠ¥ êµ¬í˜„ì„ ìœ„í•œ python ì½”ë“œì™€ ì…ë ¥ ë°›ê³  
ì¶œë ¥í•  ë²¡ì—”ë“œ í”„ë¡ íŠ¸ì—”ë“œ ì½”ë“œê°€ í•„ìš”í•´ 
ì§€ê¸ˆì€ íŒŒì´ì¬ë§Œ ë§Œë“¤ì–´ì¤˜
í¬ë¡¤ë§ ì½”ë“œë¥¼ ë§Œë“¤ë•ŒëŠ” ì§€ê¸ˆ ìˆ˜í–‰í•œ í¬ë¡¤ë§ ì½”ë“œê°€ 
ë¬´ì—‡ì„ ìœ„í•œ í¬ë¡¤ë§ì¸ì§€ í¬ë¡¤ë§í•˜ëŠ”ë° ì‹œê°„ì€ ì–¼ë§ˆë‚˜ 
ê±¸ë ¸ëŠ”ì§€ ì½˜ì†”ì—ì„œ ì•Œ ìˆ˜ ìˆê²Œ ì¶œë ¥í•´ì¤˜ 


*/


import requests
from bs4 import BeautifulSoup
import time
import urllib.parse
from collections import deque
import re
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class IMDBCrawler:
    def __init__(self):
        self.base_url = "https://www.imdb.com"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.actor_cache = {}  # ë°°ìš°ëª… -> IMDB ID ìºì‹œ
        self.movie_cache = {}  # ë°°ìš° ID -> ì˜í™” ë¦¬ìŠ¤íŠ¸ ìºì‹œ
        self.cast_cache = {}   # ì˜í™” ID -> ë°°ìš° ë¦¬ìŠ¤íŠ¸ ìºì‹œ
        
    def search_actor(self, actor_name):
        """ë°°ìš° ì´ë¦„ìœ¼ë¡œ IMDBì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë°°ìš° ID ë°˜í™˜"""
        if actor_name in self.actor_cache:
            logger.info(f"ğŸ“‹ ìºì‹œ: {actor_name} ì •ë³´ ë¡œë“œë¨")
            return self.actor_cache[actor_name]
            
        logger.info(f"ğŸ” ë°°ìš° ê²€ìƒ‰: '{actor_name}' ê²€ìƒ‰ ì¤‘...")
        start_time = time.time()
        
        search_url = f"{self.base_url}/find/?q={urllib.parse.quote(actor_name)}&ref_=nv_sr_sm"
        
        try:
            response = self.session.get(search_url)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ë°°ìš° ê²°ê³¼ì—ì„œ ì²« ë²ˆì§¸ í•­ëª© ì°¾ê¸°
            actor_links = soup.find_all('a', class_='ipc-metadata-list-summary-item__t')
            
            for link in actor_links:
                href = link.get('href', '')
                if '/name/' in href:
                    actor_id = href.split('/name/')[1].split('/')[0]
                    actor_url = f"{self.base_url}{href}"
                    
                    elapsed_time = time.time() - start_time
                    logger.info(f"âœ… ë°°ìš° ë°œê²¬: {actor_name} -> {actor_id} ({elapsed_time:.2f}ì´ˆ)")
                    
                    self.actor_cache[actor_name] = (actor_id, actor_url)
                    return actor_id, actor_url
                    
        except Exception as e:
            logger.error(f"âŒ ë°°ìš° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            
        elapsed_time = time.time() - start_time
        logger.warning(f"âŒ ë°°ìš° ê²€ìƒ‰ ì‹¤íŒ¨: '{actor_name}' ({elapsed_time:.2f}ì´ˆ)")
        return None, None
    
    def get_actor_movies(self, actor_id, actor_url, actor_name=""):
        """ë°°ìš°ì˜ ì¶œì—° ì˜í™” ëª©ë¡ ë°˜í™˜"""
        if actor_id in self.movie_cache:
            logger.info(f"ğŸ“‹ ìºì‹œ: {actor_name}ì˜ ì˜í™” ëª©ë¡ ë¡œë“œë¨")
            return self.movie_cache[actor_id]
            
        logger.info(f"ğŸ¬ {actor_name}ì˜ ì˜í™” ëª©ë¡ í¬ë¡¤ë§ ì¤‘...")
        start_time = time.time()
        
        try:
            response = self.session.get(actor_url)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            movies = []
            
            # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ì˜í™” ì œëª© ì¶”ì¶œ ì‹œë„
            # ë°©ë²• 1: ê¸°ë³¸ filmography ë§í¬
            movie_elements = soup.find_all('a', class_='ipc-metadata-list-summary-item__t')
            
            for element in movie_elements:
                href = element.get('href', '')
                if '/title/' in href:
                    movie_id = href.split('/title/')[1].split('/')[0]
                    movie_title = element.get_text(strip=True)
                    movie_url = f"{self.base_url}{href}"
                    if movie_title:  # ì œëª©ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                        movies.append((movie_id, movie_title, movie_url))
            
            # ë°©ë²• 2: ë‹¤ë¥¸ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ì‹œë„
            if not movies:
                movie_links = soup.find_all('a', href=re.compile(r'/title/tt\d+/'))
                for link in movie_links:
                    href = link.get('href', '')
                    movie_id = href.split('/title/')[1].split('/')[0]
                    movie_title = link.get_text(strip=True)
                    movie_url = f"{self.base_url}{href}"
                    if movie_title and len(movie_title) > 1:  # ì˜ë¯¸ìˆëŠ” ì œëª©ì¸ ê²½ìš°ë§Œ
                        movies.append((movie_id, movie_title, movie_url))
            
            # ë°©ë²• 3: ë” ë„“ì€ ë²”ìœ„ë¡œ ê²€ìƒ‰
            if not movies:
                all_links = soup.find_all('a')
                for link in all_links:
                    href = link.get('href', '')
                    if '/title/tt' in href:
                        try:
                            movie_id = href.split('/title/')[1].split('/')[0]
                            movie_title = link.get_text(strip=True)
                            movie_url = f"{self.base_url}{href}"
                            if movie_title and len(movie_title) > 1 and not movie_title.isdigit():
                                movies.append((movie_id, movie_title, movie_url))
                        except:
                            continue
            
            # ì¤‘ë³µ ì œê±° ë° í•„í„°ë§
            seen_movies = set()
            filtered_movies = []
            for movie_id, movie_title, movie_url in movies:
                if movie_id not in seen_movies and movie_title and len(movie_title.strip()) > 1:
                    seen_movies.add(movie_id)
                    filtered_movies.append((movie_id, movie_title.strip(), movie_url))
            
            movies = filtered_movies[:50]  # ìƒìœ„ 50ê°œ ì˜í™”ë§Œ ì„ íƒ
            
            elapsed_time = time.time() - start_time
            logger.info(f"âœ… ì˜í™” ëª©ë¡ ì™„ë£Œ: {len(movies)}í¸ ë°œê²¬ ({elapsed_time:.1f}ì´ˆ)")
            
            self.movie_cache[actor_id] = movies
            return movies
            
        except Exception as e:
            logger.error(f"âŒ ì˜í™” ëª©ë¡ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []
    
    def get_movie_cast(self, movie_id, movie_url, movie_title=""):
        """ì˜í™”ì˜ ì¶œì—° ë°°ìš° ëª©ë¡ ë°˜í™˜"""
        if movie_id in self.cast_cache:
            return self.cast_cache[movie_id]
            
        start_time = time.time()
        
        try:
            response = self.session.get(movie_url)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')
            
            cast = []
            
            # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë°°ìš° ì´ë¦„ ì¶”ì¶œ
            # ë°©ë²• 1: í‘œì¤€ cast ë§í¬
            cast_elements = soup.find_all('a', href=re.compile(r'/name/nm\d+/'))
            
            for element in cast_elements:
                href = element.get('href', '')
                if '/name/' in href:
                    actor_id = href.split('/name/')[1].split('/')[0]
                    # ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë°°ìš° ì´ë¦„ ì¶”ì¶œ ì‹œë„
                    actor_name = element.get_text(strip=True)
                    
                    # ì´ë¦„ì´ ë¹„ì–´ìˆë‹¤ë©´ ë¶€ëª¨ ìš”ì†Œì—ì„œ ì°¾ê¸°
                    if not actor_name:
                        parent = element.find_parent()
                        if parent:
                            actor_name = parent.get_text(strip=True)
                    
                    # ì´ë¦„ì´ ì—¬ì „íˆ ë¹„ì–´ìˆë‹¤ë©´ alt ì†ì„±ì—ì„œ ì°¾ê¸°
                    if not actor_name:
                        img = element.find('img')
                        if img and img.get('alt'):
                            actor_name = img.get('alt').strip()
                    
                    if actor_name and actor_id.startswith('nm') and len(actor_name) > 1:
                        cast.append((actor_id, actor_name))
            
            # ë°©ë²• 2: ì´ë¯¸ì§€ alt ì†ì„±ì—ì„œ ë°°ìš° ì´ë¦„ ì¶”ì¶œ
            if len(cast) < 5:  # ë°°ìš°ê°€ ë„ˆë¬´ ì ë‹¤ë©´ ë‹¤ë¥¸ ë°©ë²• ì‹œë„
                images = soup.find_all('img', alt=True)
                for img in images:
                    alt_text = img.get('alt', '').strip()
                    parent_link = img.find_parent('a')
                    if parent_link and '/name/nm' in parent_link.get('href', ''):
                        href = parent_link.get('href', '')
                        actor_id = href.split('/name/')[1].split('/')[0]
                        if alt_text and len(alt_text) > 1 and not alt_text.lower().startswith('poster'):
                            cast.append((actor_id, alt_text))
            
            # ì¤‘ë³µ ì œê±° ë° í•„í„°ë§
            seen_actors = set()
            filtered_cast = []
            for actor_id, actor_name in cast:
                if actor_id not in seen_actors and actor_name and len(actor_name.strip()) > 1:
                    seen_actors.add(actor_id)
                    filtered_cast.append((actor_id, actor_name.strip()))
            
            cast = filtered_cast[:30]  # ìƒìœ„ 30ëª… ë°°ìš°ë§Œ ì„ íƒ
            
            elapsed_time = time.time() - start_time
            
            self.cast_cache[movie_id] = cast
            return cast
            
        except Exception as e:
            logger.error(f"âŒ ì¶œì—°ì§„ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []

class KevinBaconGame:
    def __init__(self):
        self.crawler = IMDBCrawler()
        
    def find_connection(self, start_actor, target_actor, max_depth=6, progress_callback=None):
        """ë‘ ë°°ìš° ê°„ì˜ ì—°ê²° ê²½ë¡œ ì°¾ê¸° (BFS ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)"""
        logger.info(f"ğŸ¯ Kevin Bacon Game ì‹œì‘: '{start_actor}' â†’ '{target_actor}'")
        
        if progress_callback:
            progress_callback("starting", 0, "", "", 10.0, f"'{start_actor}'ê³¼ '{target_actor}' ì—°ê²° ì°¾ê¸° ì‹œì‘")
        
        # ì‹œì‘ ë°°ìš°ì™€ ëª©í‘œ ë°°ìš°ì˜ IMDB ID ì°¾ê¸°
        start_id, start_url = self.crawler.search_actor(start_actor)
        if not start_id:
            if progress_callback:
                progress_callback("error", 0, "", "", 0, f"'{start_actor}' ë°°ìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        target_id, target_url = self.crawler.search_actor(target_actor)
        if not target_id:
            if progress_callback:
                progress_callback("error", 0, "", "", 0, f"'{target_actor}' ë°°ìš°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        if start_id == target_id:
            if progress_callback:
                progress_callback("completed", 0, "", "", 100.0, "ë‘ ë°°ìš°ê°€ ë™ì¼í•©ë‹ˆë‹¤!")
            return []
        
        if progress_callback:
            progress_callback("searching", 0, "", "", 20.0, "ì—°ê²° ê²½ë¡œ íƒìƒ‰ ì‹œì‘")
        
        # BFSë¥¼ ìœ„í•œ íì™€ ë°©ë¬¸ ê¸°ë¡
        queue = deque([(start_id, start_actor, [])])  # (ë°°ìš°ID, ë°°ìš°ëª…, ê²½ë¡œ)
        visited_actors = {start_id}
        
        for depth in range(max_depth):
            step_progress = 20.0 + (depth / max_depth) * 70.0
            
            if progress_callback:
                progress_callback(
                    "searching", 
                    depth + 1, 
                    "", 
                    "", 
                    step_progress,
                    f"{depth + 1}ë‹¨ê³„ íƒìƒ‰ ì¤‘... (ëŒ€ê¸° ì¤‘ì¸ ë°°ìš°: {len(queue)}ëª…)"
                )
            
            level_size = len(queue)
            
            if level_size == 0:
                break
                
            for i in range(level_size):
                if not queue:
                    break
                    
                current_actor_id, current_actor_name, path = queue.popleft()
                
                if progress_callback:
                    current_progress = step_progress + (i / level_size) * (70.0 / max_depth)
                    progress_callback(
                        "searching",
                        depth + 1,
                        current_actor_name,
                        "",
                        current_progress,
                        f"'{current_actor_name}'ì˜ ì˜í™” ëª©ë¡ í™•ì¸ ì¤‘..."
                    )
                
                # í˜„ì¬ ë°°ìš°ì˜ ì˜í™” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                movies = self.crawler.get_actor_movies(current_actor_id, 
                                                     f"{self.crawler.base_url}/name/{current_actor_id}/",
                                                     current_actor_name)
                
                for j, (movie_id, movie_title, movie_url) in enumerate(movies):
                    # ì˜í™” ì œëª©ì´ ë¹„ì–´ìˆë‹¤ë©´ ê±´ë„ˆë›°ê¸°
                    if not movie_title or len(movie_title.strip()) < 2:
                        continue
                    
                    if progress_callback:
                        movie_progress = step_progress + (i / level_size + j / len(movies) / level_size) * (70.0 / max_depth)
                        progress_callback(
                            "searching",
                            depth + 1,
                            current_actor_name,
                            movie_title,
                            movie_progress,
                            f"ì˜í™” '{movie_title}' ì¶œì—°ì§„ í™•ì¸ ì¤‘..."
                        )
                    
                    # ê° ì˜í™”ì˜ ì¶œì—°ì§„ ê°€ì ¸ì˜¤ê¸°
                    cast = self.crawler.get_movie_cast(movie_id, movie_url, movie_title)
                    
                    for actor_id, actor_name in cast:
                        if actor_id == target_id:
                            # ëª©í‘œ ë°°ìš° ë°œê²¬!
                            final_path = path + [{
                                "from_actor": current_actor_name,
                                "movie": movie_title,
                                "to_actor": actor_name
                            }]
                            
                            if progress_callback:
                                progress_callback(
                                    "completed", 
                                    depth + 1,
                                    current_actor_name,
                                    movie_title,
                                    100.0,
                                    f"ì—°ê²° ë°œê²¬! {len(final_path)}ë‹¨ê³„"
                                )
                            
                            logger.info(f"ğŸ‰ ì—°ê²° ë°œê²¬: {len(final_path)}ë‹¨ê³„")
                            return final_path
                            
                        if actor_id not in visited_actors:
                            visited_actors.add(actor_id)
                            new_path = path + [{
                                "from_actor": current_actor_name,
                                "movie": movie_title,
                                "to_actor": actor_name
                            }]
                            queue.append((actor_id, actor_name, new_path))
        
        if progress_callback:
            progress_callback("completed", max_depth, "", "", 100.0, f"{max_depth}ë‹¨ê³„ ë‚´ì—ì„œ ì—°ê²°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.warning(f"âŒ {max_depth}ë‹¨ê³„ ë‚´ì—ì„œ ì—°ê²°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
        
    def print_result(self, path):
        """ê²°ê³¼ ì¶œë ¥"""
        if path is None:
            print("\nâŒ ì—°ê²°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        if len(path) == 0:
            print("\nâœ¨ ë‘ ë°°ìš°ê°€ ë™ì¼í•©ë‹ˆë‹¤.")
            return
            
        print(f"\nğŸ† ì—°ê²° ê²½ë¡œ ë°œê²¬! ({len(path)}ë‹¨ê³„)")
        print("=" * 50)
        for i, step in enumerate(path, 1):
            print(f"{i}. {step['from_actor']} â†’ ã€Œ{step['movie']}ã€ â†’ {step['to_actor']}")
        print("=" * 50)

def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    game = KevinBaconGame()
    
    print("ğŸ­ IMDB Kevin Bacon Game (BeautifulSoup)")
    print("=" * 50)
    
    start_actor = input("ê¸°ì¤€ ë°°ìš° ì´ë¦„: ").strip()
    if not start_actor:
        print("âš ï¸ ë°°ìš° ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
        
    target_actor = input("ëª©í‘œ ë°°ìš° ì´ë¦„: ").strip()
    if not target_actor:
        print("âš ï¸ ë°°ìš° ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
        
    # ì§„í–‰ìƒí™© ì½œë°± í•¨ìˆ˜
    def progress_callback(status, step, actor, movie, percentage, message):
        print(f"[{percentage:5.1f}%] {message}")
    
    # ì¼€ë¹ˆ ë² ì´ì»¨ ê²Œì„ ì‹¤í–‰
    total_start_time = time.time()
    path = game.find_connection(start_actor, target_actor, progress_callback=progress_callback)
    total_elapsed_time = time.time() - total_start_time
    
    # ê²°ê³¼ ì¶œë ¥
    game.print_result(path)
    print(f"\nâ±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_elapsed_time:.1f}ì´ˆ")

if __name__ == "__main__":
    main()
